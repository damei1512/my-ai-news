import os
import json
import datetime
import feedparser
import google.generativeai as genai
import time

# ================= é…ç½®åŒº =================
# 1. éªŒè¯ Key
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
if not GEMINI_API_KEY:
    raise ValueError("âŒ API Key æœªé…ç½®")

genai.configure(api_key=GEMINI_API_KEY)
# ç»§ç»­ä½¿ç”¨ä½ éªŒè¯è¿‡å¯ç”¨çš„ Flash æ¨¡å‹ï¼ˆçœé’±ä¸”å¿«ï¼‰
MODEL_NAME = 'gemini-flash-latest'

# ================= æ ¸å¿ƒé€»è¾‘ =================

def get_current_date_info():
    """è·å–å½“å‰æ—¥æœŸå’Œæ˜ŸæœŸå‡ ï¼ˆä¸­æ–‡ï¼‰"""
    now = datetime.datetime.now()
    # ä¿®æ­£æ—¶åŒºï¼šGitHub Actions é»˜è®¤æ˜¯ UTCï¼Œæˆ‘ä»¬éœ€è¦ +8 å°æ—¶å˜æˆåŒ—äº¬æ—¶é—´
    beijing_time = now + datetime.timedelta(hours=8)
    date_str = beijing_time.strftime("%Y-%m-%d")
    
    week_map = {0: "å‘¨ä¸€", 1: "å‘¨äºŒ", 2: "å‘¨ä¸‰", 3: "å‘¨å››", 4: "å‘¨äº”", 5: "å‘¨å…­", 6: "å‘¨æ—¥"}
    week_str = week_map[beijing_time.weekday()]
    
    return date_str, week_str

def get_latest_news():
    print("ğŸ“¡ æ­£åœ¨æŠ“å– RSS...")
    rss_urls = [
        "https://techcrunch.com/category/artificial-intelligence/feed/",
        "https://www.wired.com/feed/tag/ai/latest/rss",
        "https://openai.com/index/rss.xml"
    ]
    
    articles = []
    for url in rss_urls:
        try:
            feed = feedparser.parse(url)
            print(f"   - è¿æ¥ {url} æˆåŠŸ")
            for entry in feed.entries[:2]:
                # æ‹¼æ¥é“¾æ¥ï¼Œç¡®ä¿ AI èƒ½è¯»å–åˆ°
                articles.append(f"æ ‡é¢˜: {entry.title}\né“¾æ¥: {entry.link}\nç®€ä»‹: {entry.summary[:200]}")
        except Exception as e:
            print(f"   âŒ è¿æ¥ {url} å¤±è´¥: {e}")

    if not articles:
        print("âš ï¸ æœªæŠ“å–åˆ°æ–°é—»ï¼Œç”Ÿæˆå ä½æ•°æ®")
        return "Title: No News Today\nLink: #\nSummary: System is running but no RSS updates found."
    
    return "\n\n---\n\n".join(articles)

def summarize_with_gemini(text_content):
    print(f"ğŸ¤– æ­£åœ¨å‘¼å« {MODEL_NAME}...")
    try:
        model = genai.GenerativeModel(MODEL_NAME)
        
        prompt = f"""
        ä½ æ˜¯ä¸€ä¸ªç§‘æŠ€ä¸»ç¼–ã€‚è¯·å°†ä»¥ä¸‹è‹±æ–‡æ–°é—»ç”Ÿæˆä¸ºä¸­æ–‡æ—¥æŠ¥æ‘˜è¦ï¼ˆJSONæ ¼å¼ï¼‰ã€‚
        
        ã€ä¸¥æ ¼è¦æ±‚ã€‘
        1. è¾“å‡ºå¿…é¡»æ˜¯çº¯ JSON åˆ—è¡¨ï¼Œä¸è¦ Markdown æ ‡è®°ã€‚
        2. ä¿ç•™åŸæ–‡ Linkã€‚
        
        æ ¼å¼ç¤ºä¾‹ï¼š
        [
            {{
                "tag": "AIå¤§äº‹ä»¶",
                "title": "ä¸­æ–‡æ ‡é¢˜",
                "link": "https://...",
                "summary": "ä¸­æ–‡æ‘˜è¦",
                "comment": "ä¸€å¥è¯æ¯’èˆŒç‚¹è¯„"
            }}
        ]

        æ–°é—»å†…å®¹ï¼š
        {text_content}
        """
        
        time.sleep(2) # é˜²å¹¶å‘é™åˆ¶
        response = model.generate_content(prompt)
        text = response.text.strip()
        
        # å¼ºåŠ›æ¸…æ´—æ ¼å¼
        if text.startswith("```json"): text = text[7:]
        if text.startswith("```"): text = text[3:]
        if text.endswith("```"): text = text[:-3]
        
        return json.loads(text)
        
    except Exception as e:
        print(f"âŒ API é”™è¯¯: {e}")
        return []

if __name__ == "__main__":
    # 1. å‡†å¤‡åŸºç¡€æ•°æ®
    today_date, today_week = get_current_date_info()
    history_file = 'news.json'
    
    # 2. è¯»å–æ—§æ¡£æ¡ˆ (å¸¦å®¹é”™å¤„ç†)
    archive_data = {}
    if os.path.exists(history_file):
        try:
            with open(history_file, 'r', encoding='utf-8') as f:
                content = json.load(f)
                # æ£€æŸ¥æ ¼å¼æ˜¯å¦ä¸ºæ–°ç‰ˆå­—å…¸æ ¼å¼ï¼Œå¦‚æœä¸æ˜¯åˆ™ä¸¢å¼ƒæ—§æ•°æ®
                if isinstance(content, dict) and not "news" in content: 
                    archive_data = content
                else:
                    print("âš ï¸ æ—§æ•°æ®æ ¼å¼ä¸å…¼å®¹ï¼Œå·²é‡ç½®æ¡£æ¡ˆåº“")
        except:
            print("âš ï¸ è¯»å–æ¡£æ¡ˆå¤±è´¥ï¼Œé‡ç½®æ¡£æ¡ˆåº“")

    # 3. ç”Ÿæˆä»Šæ—¥æ–°é—»
    print(f"ğŸ“… æ­£åœ¨ç”Ÿæˆ {today_date} ({today_week}) çš„æ—¥æŠ¥...")
    today_news = summarize_with_gemini(get_latest_news())
    
    if today_news:
        archive_data[today_date] = {
            "week": today_week,
            "articles": today_news
        }
    
    # 4. æ‰§è¡Œâ€œ7å¤©æ»šåŠ¨æ¸…æ´—â€ç­–ç•¥
    # æŒ‰æ—¥æœŸå€’åºæ’åˆ—
    sorted_dates = sorted(archive_data.keys(), reverse=True)
    # åªä¿ç•™å‰7ä¸ª
    keep_dates = sorted_dates[:7]
    final_data = {d: archive_data[d] for d in keep_dates}
    
    # 5. ä¿å­˜
    with open(history_file, 'w', encoding='utf-8') as f:
        json.dump(final_data, f, ensure_ascii=False, indent=2)
        
    print(f"âœ… å­˜æ¡£å®Œæˆï¼å½“å‰ä¿ç•™æ—¥æœŸ: {keep_dates}")
