import os
import json
import datetime
import feedparser
import google.generativeai as genai
import time

# 1. éªŒè¯ Key
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
if not GEMINI_API_KEY:
    raise ValueError("âŒ API Key æœªé…ç½®")

genai.configure(api_key=GEMINI_API_KEY)
MODEL_NAME = 'gemini-flash-latest'

def get_latest_news():
    print("ğŸ“¡ æ­£åœ¨æŠ“å– RSS...")
    rss_urls = [
        "https://techcrunch.com/category/artificial-intelligence/feed/",
        "https://www.wired.com/feed/tag/ai/latest/rss",
        "https://openai.com/index/rss.xml"
    ]
    articles = []
    for url in rss_urls:
        try:
            feed = feedparser.parse(url)
            for entry in feed.entries[:2]:
                articles.append(f"æ ‡é¢˜: {entry.title}\né“¾æ¥: {entry.link}\nç®€ä»‹: {entry.summary[:150]}")
        except: continue
    return "\n\n---\n\n".join(articles) if articles else "Title: AI update.\nLink: #\nSummary: Daily update active."

def summarize_with_gemini(text_content):
    print(f"ğŸ¤– æ­£åœ¨å‘¼å« {MODEL_NAME}...")
    try:
        model = genai.GenerativeModel(MODEL_NAME)
        prompt = f"è¯·å°†ä»¥ä¸‹è‹±æ–‡æ–°é—»ç”Ÿæˆä¸ºä¸­æ–‡æ—¥æŠ¥æ‘˜è¦ï¼ˆJSONæ ¼å¼åˆ—è¡¨ï¼‰ã€‚è¦æ±‚ï¼šä¿ç•™linkå­—æ®µï¼Œä¸è¦Markdownæ ‡è®°ã€‚æ ¼å¼ï¼š[ {{ 'tag': '', 'title': '', 'link': '', 'summary': '', 'comment': '' }} ]\nå†…å®¹ï¼š{text_content}"
        response = model.generate_content(prompt)
        text = response.text.strip()
        if text.startswith("```json"): text = text[7:]
        if text.startswith("```"): text = text[3:]
        if text.endswith("```"): text = text[:-3]
        return json.loads(text)
    except: return []

if __name__ == "__main__":
    # 1. è·å–ä»Šå¤©æ—¥æœŸå’Œæ˜ŸæœŸ
    now = datetime.datetime.now()
    date_str = now.strftime("%Y-%m-%d")
    week_map = {0: "å‘¨ä¸€", 1: "å‘¨äºŒ", 2: "å‘¨ä¸‰", 3: "å‘¨å››", 4: "å‘¨äº”", 5: "å‘¨å…­", 6: "å‘¨æ—¥"}
    day_info = week_map[now.weekday()]

    # 2. è¯»å–ç°æœ‰æ•°æ®
    history_file = 'news.json'
    if os.path.exists(history_file):
        with open(history_file, 'r', encoding='utf-8') as f:
            try:
                all_data = json.load(f)
                # å…¼å®¹æ—§ç‰ˆæœ¬æ ¼å¼
                if isinstance(all_data, dict) and "news" in all_data: all_data = {}
            except: all_data = {}
    else:
        all_data = {}

    # 3. æŠ“å–å¹¶ç”Ÿæˆä»Šå¤©çš„æ–°é—»
    today_articles = summarize_with_gemini(get_latest_news())
    
    if today_articles:
        all_data[date_str] = {
            "day_info": day_info,
            "articles": today_articles
        }

    # 4. åªä¿ç•™æœ€è¿‘ 7 å¤©
    sorted_dates = sorted(all_data.keys(), reverse=True)
    final_data = {d: all_data[d] for d in sorted_dates[:7]}

    # 5. ä¿å­˜
    with open(history_file, 'w', encoding='utf-8') as f:
        json.dump(final_data, f, ensure_ascii=False, indent=2)
    print(f"âœ… æ›´æ–°æˆåŠŸï¼š{date_str}")
