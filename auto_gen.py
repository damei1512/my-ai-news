import os
import json
import datetime
import feedparser
import google.generativeai as genai
import time
import pytz

# ================= é…ç½®åŒº =================
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
if not GEMINI_API_KEY:
    raise ValueError("âŒ API Key æœªé…ç½®")

genai.configure(api_key=GEMINI_API_KEY)
MODEL_NAME = 'gemini-flash-latest'

# ================= æ ¸å¿ƒé€»è¾‘ =================

def get_current_date_info():
    """è·å–åŒ—äº¬æ—¶é—´æ—¥æœŸå’Œæ˜ŸæœŸ"""
    beijing_tz = pytz.timezone('Asia/Shanghai')
    now = datetime.datetime.now(beijing_tz)
    date_str = now.strftime("%Y-%m-%d")
    week_map = {0: "å‘¨ä¸€", 1: "å‘¨äºŒ", 2: "å‘¨ä¸‰", 3: "å‘¨å››", 4: "å‘¨äº”", 5: "å‘¨å…­", 6: "å‘¨æ—¥"}
    week_str = week_map[now.weekday()]
    return date_str, week_str

def get_latest_news():
    print("ğŸ“¡ æ­£åœ¨æŠ“å–å…¨çƒ RSS æº...")
    rss_urls = [
        # --- å›½å¤–æº ---
        "https://techcrunch.com/category/artificial-intelligence/feed/",
        "https://www.wired.com/feed/tag/ai/latest/rss",
        "https://openai.com/index/rss.xml",
        
        # --- å›½å†…æº (æ–°å¢) ---
        "https://36kr.com/feed",  # 36Kr (åŒ…å«å›½å†… AI æŠ•èèµ„å’Œäº§å“åŠ¨æ€)
        "https://www.ifanr.com/feed", # çˆ±èŒƒå„¿ (è¾ƒå¤š AI ç¡¬ä»¶å’Œåº”ç”¨æŠ¥é“)
    ]
    
    articles = []
    for url in rss_urls:
        try:
            # è®¾ç½®è¶…æ—¶é˜²æ­¢å¡æ­»
            feed = feedparser.parse(url)
            print(f"   - è¿æ¥ {url} æˆåŠŸ")
            
            # æ¯ä¸ªæºåªå–å‰ 2 æ¡ï¼Œé˜²æ­¢ Token çˆ†ç‚¸
            for entry in feed.entries[:2]:
                articles.append(f"æ ‡é¢˜: {entry.title}\né“¾æ¥: {entry.link}\nç®€ä»‹: {entry.summary[:200]}")
        except Exception as e:
            print(f"   âŒ è¿æ¥ {url} å¤±è´¥: {e}")

    if not articles:
        return "Title: System Update\nLink: #\nSummary: No RSS updates found today."
    
    return "\n\n---\n\n".join(articles)

def summarize_with_gemini(text_content):
    print(f"ğŸ¤– æ­£åœ¨å‘¼å« {MODEL_NAME} è¿›è¡ŒåŒºåŸŸåˆ†ç±»ä¸æ€»ç»“...")
    try:
        model = genai.GenerativeModel(MODEL_NAME)
        
        prompt = f"""
        ä½ æ˜¯ä¸€ä¸ªç§‘æŠ€ä¸»ç¼–ã€‚è¯·å°†ä»¥ä¸‹å…¨çƒæ–°é—»ç”Ÿæˆä¸ºä¸­æ–‡æ—¥æŠ¥æ‘˜è¦ï¼ˆJSONæ ¼å¼ï¼‰ã€‚

        ã€æ ¸å¿ƒè¦æ±‚ã€‘
        1. å¿…é¡»åˆ¤æ–­æ–°é—»çš„ã€æ‰€å±åŒºåŸŸã€‘ï¼š
           - å¦‚æœæ˜¯å‘ç”Ÿåœ¨ä¸­å›½ã€æˆ–æ¶‰åŠä¸­å›½å…¬å¸çš„ AI æ–°é—»ï¼Œcategory å¡« "å›½å†…"ã€‚
           - å¦åˆ™ï¼ˆå¦‚ OpenAI, Google, ç¾å›½åˆåˆ›å…¬å¸ç­‰ï¼‰ï¼Œcategory å¡« "å›½å¤–"ã€‚
        2. ä¿ç•™åŸæ–‡ Linkã€‚
        3. è¾“å‡ºçº¯ JSON åˆ—è¡¨ï¼Œæ—  Markdownã€‚

        JSON æ ¼å¼ç¤ºä¾‹ï¼š
        [
            {{
                "category": "å›½å†…",  <-- å¿…é¡»ä¸¥æ ¼ä» ["å›½å†…", "å›½å¤–"] ä¸­äºŒé€‰ä¸€
                "tag": "å¤§æ¨¡å‹",
                "title": "ä¸­æ–‡æ ‡é¢˜",
                "link": "https://...",
                "summary": "ä¸­æ–‡æ‘˜è¦",
                "comment": "æ¯’èˆŒç‚¹è¯„"
            }}
        ]

        æ–°é—»å†…å®¹ï¼š
        {text_content}
        """
        
        time.sleep(2) 
        response = model.generate_content(prompt)
        text = response.text.strip()
        
        if text.startswith("```json"): text = text[7:]
        if text.startswith("```"): text = text[3:]
        if text.endswith("```"): text = text[:-3]
        
        return json.loads(text)
        
    except Exception as e:
        print(f"âŒ API é”™è¯¯: {e}")
        return []

if __name__ == "__main__":
    today_date, today_week = get_current_date_info()
    history_file = 'news.json'
    
    archive_data = {}
    if os.path.exists(history_file):
        try:
            with open(history_file, 'r', encoding='utf-8') as f:
                content = json.load(f)
                if isinstance(content, dict) and not "news" in content: archive_data = content
        except: pass

    # ç”Ÿæˆä»Šæ—¥æ–°é—»
    print(f"ğŸ“… ç”Ÿæˆ {today_date} ({today_week})...")
    today_news = summarize_with_gemini(get_latest_news())
    
    if today_news:
        archive_data[today_date] = {
            "week": today_week,
            "articles": today_news
        }
    
    # 7å¤©æ»šåŠ¨æ¸…æ´—
    sorted_dates = sorted(archive_data.keys(), reverse=True)
    final_data = {d: archive_data[d] for d in sorted_dates[:7]}
    
    with open(history_file, 'w', encoding='utf-8') as f:
        json.dump(final_data, f, ensure_ascii=False, indent=2)
        
    print(f"âœ… å®Œæˆï¼")
